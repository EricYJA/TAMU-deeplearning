{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45d0a7fc",
   "metadata": {},
   "source": [
    "## CSCE636 Deep Learning - Dr. Anxiao Jiang\n",
    "- Changcheng Yuan\n",
    "- UIN: 53500517"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e273513c",
   "metadata": {},
   "source": [
    "Check out the Jupyter notebook for Chapter 13 at https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/chapter13_timeseries-forecasting.ipynb . It has tried 6 methods for the temperature prediction problem: Try 1 (A common-sense, non-machine learning baseline method), Try 2 (A fully connected neural network), Try 3 (1-d convolutional neural networks), Try 4 (LSTM with recurrent dropout), Try 5 (stacking RNN layers), Try 6 (Bidirectional RNN).\n",
    "\n",
    "Your task: use the above 6 methods to predict the temperature in 48 hours (instead of 24 hours). In the Jupyter notebook, include your code as well as the performance of the 6 methods.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0937d89",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'typing_extensions'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "!cd ../data/chapter13 && wget https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip\n",
    "!cd ../data/chapter13 && unzip jena_climate_2009_2016.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f980bcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ericycc/.conda/envs/ml-tf-env/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs found: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Built with CUDA: True\n",
      "GPU available: True\n",
      "Default GPU device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "import tensorflow as tf\n",
    "\n",
    "# List all GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"GPUs found:\", gpus)\n",
    "\n",
    "# Quick check\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "print(\"GPU available:\", len(gpus) > 0)\n",
    "# Or get the default device name\n",
    "print(\"Default GPU device:\", tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf4f2fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '../data/chapter13/jena_climate_2009_2016.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95b3ae7b",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 420451 timesteps across 14 sensors\n",
      "Train/val/test samples: 210225/105112/105114\n",
      "Forecast horizon: 48 hours (delay steps: 1002)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "with open(datapath) as f:\n",
    "    data = f.read().strip().split(\"\\n\")\n",
    "\n",
    "header = data[0].split(\",\")\n",
    "lines = data[1:]\n",
    "num_features = len(header) - 1\n",
    "\n",
    "raw_data = np.zeros((len(lines), num_features), dtype=np.float32)\n",
    "temperature = np.zeros((len(lines),), dtype=np.float32)\n",
    "for idx, line in enumerate(lines):\n",
    "    values = [float(x) for x in line.split(\",\")[1:]]\n",
    "    temperature[idx] = values[1]\n",
    "    raw_data[idx] = values\n",
    "\n",
    "num_train_samples = int(0.5 * len(raw_data))\n",
    "num_val_samples = int(0.25 * len(raw_data))\n",
    "num_test_samples = len(raw_data) - num_train_samples - num_val_samples\n",
    "\n",
    "mean = raw_data[:num_train_samples].mean(axis=0)\n",
    "std = raw_data[:num_train_samples].std(axis=0)\n",
    "std[std == 0] = 1.0\n",
    "raw_data = (raw_data - mean) / std\n",
    "\n",
    "sampling_rate = 6\n",
    "time_steps = 120\n",
    "forecast_horizon_hours = 48\n",
    "# Offset between the last input time step and the prediction target\n",
    "sequence_delay = sampling_rate * (time_steps + forecast_horizon_hours - 1)\n",
    "batch_size = 256\n",
    "\n",
    "train_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "    raw_data[:-sequence_delay],\n",
    "    targets=temperature[sequence_delay:],\n",
    "    sampling_rate=sampling_rate,\n",
    "    sequence_length=time_steps,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    start_index=0,\n",
    "    end_index=num_train_samples,\n",
    ")\n",
    "\n",
    "val_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "    raw_data[:-sequence_delay],\n",
    "    targets=temperature[sequence_delay:],\n",
    "    sampling_rate=sampling_rate,\n",
    "    sequence_length=time_steps,\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size,\n",
    "    start_index=num_train_samples,\n",
    "    end_index=num_train_samples + num_val_samples,\n",
    ")\n",
    "\n",
    "test_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "    raw_data[:-sequence_delay],\n",
    "    targets=temperature[sequence_delay:],\n",
    "    sampling_rate=sampling_rate,\n",
    "    sequence_length=time_steps,\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size,\n",
    "    start_index=num_train_samples + num_val_samples,\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(lines)} timesteps across {num_features} sensors\")\n",
    "print(f\"Train/val/test samples: {num_train_samples}/{num_val_samples}/{num_test_samples}\")\n",
    "print(f\"Forecast horizon: {forecast_horizon_hours} hours (delay steps: {sequence_delay})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe61519",
   "metadata": {},
   "source": [
    "### Try 1\n",
    "\n",
    "Simple non-linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66133f4b",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples used: 60000\n",
      "Train MAE: 3.32 °C\n",
      "Validation MAE: 3.06 °C\n",
      "Test MAE: 3.28 °C\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "\n",
    "history_hours = 48\n",
    "max_train_samples = 60000\n",
    "\n",
    "\n",
    "def collect_numpy(dataset, limit=None):\n",
    "    features, targets = [], []\n",
    "    seen = 0\n",
    "    for samples, target in dataset:\n",
    "        samples_np = np.asarray(samples)\n",
    "        target_np = np.asarray(target)\n",
    "        temp_history = samples_np[:, -history_hours:, 1]\n",
    "        features.append(temp_history)\n",
    "        targets.append(target_np)\n",
    "        seen += len(target_np)\n",
    "        if limit and seen >= limit:\n",
    "            break\n",
    "    X = np.concatenate(features, axis=0)\n",
    "    y = np.concatenate(targets, axis=0)\n",
    "    if limit:\n",
    "        X = X[:limit]\n",
    "        y = y[:limit]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def evaluate_mae(model, dataset):\n",
    "    total_abs_err = 0.0\n",
    "    samples_seen = 0\n",
    "    for samples, target in dataset:\n",
    "        features = np.asarray(samples)[:, -history_hours:, 1]\n",
    "        preds = model.predict(features)\n",
    "        target_np = np.asarray(target)\n",
    "        total_abs_err += np.sum(np.abs(preds - target_np))\n",
    "        samples_seen += len(target_np)\n",
    "    return total_abs_err / samples_seen\n",
    "\n",
    "\n",
    "train_X, train_y = collect_numpy(train_dataset, limit=max_train_samples)\n",
    "\n",
    "model = Pipeline(\n",
    "    [\n",
    "        (\"poly\", PolynomialFeatures(degree=2, include_bias=False)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"regressor\", Ridge(alpha=100.0)),\n",
    "    ]\n",
    ")\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "train_mae = mean_absolute_error(train_y, model.predict(train_X))\n",
    "val_mae = evaluate_mae(model, val_dataset)\n",
    "test_mae = evaluate_mae(model, test_dataset)\n",
    "\n",
    "print(f\"Train samples used: {len(train_X)}\")\n",
    "print(f\"Train MAE: {train_mae:.2f} °C\")\n",
    "print(f\"Validation MAE: {val_mae:.2f} °C\")\n",
    "print(f\"Test MAE: {test_mae:.2f} °C\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "try2-md",
   "metadata": {},
   "source": [
    "### Try 2\n",
    "\n",
    "Simple dense network using MSE for training and MAE for human readable result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "try2-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1761168554.035713   43245 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "819/819 [==============================] - 4s 4ms/step - loss: 8.5069 - mse: 8.5069 - mae: 2.1502 - val_loss: 22.4458 - val_mse: 22.4458 - val_mae: 3.7084\n",
      "Epoch 2/20\n",
      "819/819 [==============================] - 3s 3ms/step - loss: 1.5929 - mse: 1.5929 - mae: 0.9663 - val_loss: 22.3778 - val_mse: 22.3778 - val_mae: 3.7183\n",
      "Epoch 3/20\n",
      "819/819 [==============================] - 3s 4ms/step - loss: 0.9794 - mse: 0.9794 - mae: 0.7655 - val_loss: 21.7608 - val_mse: 21.7608 - val_mae: 3.6696\n",
      "Epoch 4/20\n",
      "819/819 [==============================] - 3s 3ms/step - loss: 0.7756 - mse: 0.7756 - mae: 0.6825 - val_loss: 21.7489 - val_mse: 21.7489 - val_mae: 3.6531\n",
      "Epoch 5/20\n",
      "819/819 [==============================] - 3s 4ms/step - loss: 0.7107 - mse: 0.7107 - mae: 0.6518 - val_loss: 21.2503 - val_mse: 21.2503 - val_mae: 3.6159\n",
      "Epoch 6/20\n",
      "394/819 [=============>................] - ETA: 0s - loss: 0.6201 - mse: 0.6201 - mae: 0.6092"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 38\u001b[0m\n\u001b[1;32m     26\u001b[0m dense_model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     27\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m),\n\u001b[1;32m     28\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     29\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     32\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m callbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(\n\u001b[1;32m     33\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_mae\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     34\u001b[0m     patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     35\u001b[0m     restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     36\u001b[0m )\n\u001b[0;32m---> 38\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mdense_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflattened_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflattened_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m test_loss, test_mse, test_mae \u001b[38;5;241m=\u001b[39m dense_model\u001b[38;5;241m.\u001b[39mevaluate(flattened_test)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain MAE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhistory\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m °C\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/ml-tf-env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.conda/envs/ml-tf-env/lib/python3.10/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.conda/envs/ml-tf-env/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.conda/envs/ml-tf-env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.conda/envs/ml-tf-env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.conda/envs/ml-tf-env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/ml-tf-env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.conda/envs/ml-tf-env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/.conda/envs/ml-tf-env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/ml-tf-env/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/.conda/envs/ml-tf-env/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "\n",
    "\n",
    "def flatten_dataset(dataset):\n",
    "    return dataset.map(lambda x, y: (tf.reshape(x, (tf.shape(x)[0], -1)), y))\n",
    "\n",
    "\n",
    "flattened_train = flatten_dataset(train_dataset).prefetch(tf.data.AUTOTUNE)\n",
    "flattened_val = flatten_dataset(val_dataset).prefetch(tf.data.AUTOTUNE)\n",
    "flattened_test = flatten_dataset(test_dataset).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "input_dim = time_steps * num_features\n",
    "\n",
    "dense_model = models.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        layers.Dense(256, activation=\"relu\"),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dense_model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"mse\",\n",
    "    metrics=[\"mse\", \"mae\"],\n",
    ")\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor=\"val_mae\",\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "history = dense_model.fit(\n",
    "    flattened_train,\n",
    "    validation_data=flattened_val,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "\n",
    "test_loss, test_mse, test_mae = dense_model.evaluate(flattened_test)\n",
    "print(f\"Train MAE: {history.history['mae'][-1]:.2f} °C\")\n",
    "print(f\"Validation MAE: {history.history['val_mae'][-1]:.2f} °C\")\n",
    "print(f\"Test MAE: {test_mae:.2f} °C\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "try3-md",
   "metadata": {},
   "source": [
    "### Try 3\n",
    "\n",
    "1D convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "try3-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "819/819 [==============================] - 4s 4ms/step - loss: 26.7248 - mae: 4.0525 - val_loss: 21.7124 - val_mae: 3.6593\n",
      "Epoch 2/20\n",
      "819/819 [==============================] - 4s 4ms/step - loss: 26.7248 - mae: 4.0525 - val_loss: 21.7124 - val_mae: 3.6593\n",
      "Epoch 2/20\n",
      "819/819 [==============================] - 3s 4ms/step - loss: 17.2363 - mae: 3.3040 - val_loss: 22.9234 - val_mae: 3.7617\n",
      "Epoch 3/20\n",
      "819/819 [==============================] - 3s 4ms/step - loss: 17.2363 - mae: 3.3040 - val_loss: 22.9234 - val_mae: 3.7617\n",
      "Epoch 3/20\n",
      "819/819 [==============================] - 3s 4ms/step - loss: 15.0088 - mae: 3.0766 - val_loss: 23.2874 - val_mae: 3.7093\n",
      "Epoch 4/20\n",
      "819/819 [==============================] - 3s 4ms/step - loss: 15.0088 - mae: 3.0766 - val_loss: 23.2874 - val_mae: 3.7093\n",
      "Epoch 4/20\n",
      "819/819 [==============================] - 3s 4ms/step - loss: 13.7035 - mae: 2.9317 - val_loss: 23.3120 - val_mae: 3.8008\n",
      "Epoch 5/20\n",
      "819/819 [==============================] - 3s 4ms/step - loss: 13.7035 - mae: 2.9317 - val_loss: 23.3120 - val_mae: 3.8008\n",
      "Epoch 5/20\n",
      "819/819 [==============================] - 3s 4ms/step - loss: 12.7704 - mae: 2.8225 - val_loss: 20.8773 - val_mae: 3.6062\n",
      "Epoch 6/20\n",
      "819/819 [==============================] - 3s 4ms/step - loss: 12.7704 - mae: 2.8225 - val_loss: 20.8773 - val_mae: 3.6062\n",
      "Epoch 6/20\n",
      "819/819 [==============================] - 3s 4ms/step - loss: 12.0872 - mae: 2.7393 - val_loss: 21.4753 - val_mae: 3.6310\n",
      "Epoch 7/20\n",
      "819/819 [==============================] - 3s 4ms/step - loss: 12.0872 - mae: 2.7393 - val_loss: 21.4753 - val_mae: 3.6310\n",
      "Epoch 7/20\n",
      "819/819 [==============================] - 3s 4ms/step - loss: 11.5291 - mae: 2.6740 - val_loss: 22.7263 - val_mae: 3.7289\n",
      "Epoch 8/20\n",
      "819/819 [==============================] - 3s 4ms/step - loss: 11.5291 - mae: 2.6740 - val_loss: 22.7263 - val_mae: 3.7289\n",
      "Epoch 8/20\n",
      "819/819 [==============================] - 3s 4ms/step - loss: 11.0612 - mae: 2.6199 - val_loss: 22.7498 - val_mae: 3.7557\n",
      "Epoch 9/20\n",
      "819/819 [==============================] - 3s 4ms/step - loss: 11.0612 - mae: 2.6199 - val_loss: 22.7498 - val_mae: 3.7557\n",
      "Epoch 9/20\n",
      "819/819 [==============================] - 3s 3ms/step - loss: 10.6719 - mae: 2.5716 - val_loss: 22.5056 - val_mae: 3.7476\n",
      "Epoch 10/20\n",
      "819/819 [==============================] - 3s 3ms/step - loss: 10.6719 - mae: 2.5716 - val_loss: 22.5056 - val_mae: 3.7476\n",
      "Epoch 10/20\n",
      "819/819 [==============================] - 3s 4ms/step - loss: 10.3544 - mae: 2.5321 - val_loss: 24.3774 - val_mae: 3.8577\n",
      "819/819 [==============================] - 3s 4ms/step - loss: 10.3544 - mae: 2.5321 - val_loss: 24.3774 - val_mae: 3.8577\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 22.0820 - mae: 3.7204\n",
      "Train MAE: 2.53 °C\n",
      "Validation MAE: 3.86 °C\n",
      "Test MAE: 3.72 °C\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 22.0820 - mae: 3.7204\n",
      "Train MAE: 2.53 °C\n",
      "Validation MAE: 3.86 °C\n",
      "Test MAE: 3.72 °C\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model, callbacks, layers, optimizers\n",
    "\n",
    "conv_train = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "conv_val = val_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "conv_test = test_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "inputs = Input(shape=(time_steps, num_features))\n",
    "x = layers.Conv1D(8, 24, activation=\"relu\")(inputs)\n",
    "x = layers.MaxPooling1D(2)(x)\n",
    "x = layers.Conv1D(8, 12, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling1D(2)(x)\n",
    "x = layers.Conv1D(8, 6, activation=\"relu\")(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "outputs = layers.Dense(1)(x)\n",
    "conv_model = Model(inputs, outputs)\n",
    "\n",
    "conv_model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"mse\",\n",
    "    metrics=[\"mae\"],\n",
    ")\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor=\"val_mae\",\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "history = conv_model.fit(\n",
    "    conv_train,\n",
    "    validation_data=conv_val,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "\n",
    "test_loss, test_mae = conv_model.evaluate(conv_test)\n",
    "print(f\"Train MAE: {history.history['mae'][-1]:.2f} °C\")\n",
    "print(f\"Validation MAE: {history.history['val_mae'][-1]:.2f} °C\")\n",
    "print(f\"Test MAE: {test_mae:.2f} °C\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "try4-md",
   "metadata": {},
   "source": [
    "### Try 4\n",
    "\n",
    "LSTM with recurrent dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "try4-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/20\n",
      "Epoch 1/20\n",
      "819/819 [==============================] - 56s 67ms/step - loss: 35.3035 - mae: 4.4916 - val_loss: 17.2356 - val_mae: 3.2307\n",
      "Epoch 2/20\n",
      "819/819 [==============================] - 56s 67ms/step - loss: 35.3035 - mae: 4.4916 - val_loss: 17.2356 - val_mae: 3.2307\n",
      "Epoch 2/20\n",
      "819/819 [==============================] - 55s 67ms/step - loss: 21.0864 - mae: 3.5989 - val_loss: 15.9922 - val_mae: 3.1183\n",
      "Epoch 3/20\n",
      "819/819 [==============================] - 55s 67ms/step - loss: 21.0864 - mae: 3.5989 - val_loss: 15.9922 - val_mae: 3.1183\n",
      "Epoch 3/20\n",
      "819/819 [==============================] - 55s 67ms/step - loss: 19.9845 - mae: 3.5062 - val_loss: 15.8539 - val_mae: 3.1060\n",
      "Epoch 4/20\n",
      "819/819 [==============================] - 55s 67ms/step - loss: 19.9845 - mae: 3.5062 - val_loss: 15.8539 - val_mae: 3.1060\n",
      "Epoch 4/20\n",
      "819/819 [==============================] - 55s 67ms/step - loss: 18.8643 - mae: 3.4021 - val_loss: 15.5402 - val_mae: 3.0776\n",
      "Epoch 5/20\n",
      "819/819 [==============================] - 55s 67ms/step - loss: 18.8643 - mae: 3.4021 - val_loss: 15.5402 - val_mae: 3.0776\n",
      "Epoch 5/20\n",
      "819/819 [==============================] - 55s 67ms/step - loss: 18.2988 - mae: 3.3445 - val_loss: 15.5770 - val_mae: 3.0922\n",
      "Epoch 6/20\n",
      "819/819 [==============================] - 55s 67ms/step - loss: 18.2988 - mae: 3.3445 - val_loss: 15.5770 - val_mae: 3.0922\n",
      "Epoch 6/20\n",
      "819/819 [==============================] - 55s 67ms/step - loss: 17.6314 - mae: 3.2802 - val_loss: 15.4021 - val_mae: 3.0725\n",
      "Epoch 7/20\n",
      "819/819 [==============================] - 55s 67ms/step - loss: 17.6314 - mae: 3.2802 - val_loss: 15.4021 - val_mae: 3.0725\n",
      "Epoch 7/20\n",
      "819/819 [==============================] - 55s 67ms/step - loss: 17.1580 - mae: 3.2363 - val_loss: 15.1410 - val_mae: 3.0518\n",
      "Epoch 8/20\n",
      "819/819 [==============================] - 55s 67ms/step - loss: 17.1580 - mae: 3.2363 - val_loss: 15.1410 - val_mae: 3.0518\n",
      "Epoch 8/20\n",
      "819/819 [==============================] - 55s 67ms/step - loss: 16.9492 - mae: 3.2148 - val_loss: 15.8922 - val_mae: 3.1056\n",
      "Epoch 9/20\n",
      "819/819 [==============================] - 55s 67ms/step - loss: 16.9492 - mae: 3.2148 - val_loss: 15.8922 - val_mae: 3.1056\n",
      "Epoch 9/20\n",
      "819/819 [==============================] - 55s 67ms/step - loss: 16.1298 - mae: 3.1248 - val_loss: 15.9763 - val_mae: 3.1246\n",
      "819/819 [==============================] - 55s 67ms/step - loss: 16.1298 - mae: 3.1248 - val_loss: 15.9763 - val_mae: 3.1246\n",
      "404/404 [==============================] - 6s 14ms/step - loss: 17.5953 - mae: 3.3301\n",
      "Train MAE: 3.12 °C\n",
      "Validation MAE: 3.12 °C\n",
      "Test MAE: 3.33 °C\n",
      "404/404 [==============================] - 6s 14ms/step - loss: 17.5953 - mae: 3.3301\n",
      "Train MAE: 3.12 °C\n",
      "Validation MAE: 3.12 °C\n",
      "Test MAE: 3.33 °C\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model, callbacks, layers, optimizers\n",
    "\n",
    "lstm_train = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "lstm_val = val_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "lstm_test = test_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "debug_batches = None # disable debug\n",
    "if debug_batches:\n",
    "    lstm_train = lstm_train.take(debug_batches)\n",
    "    lstm_val = lstm_val.take(max(1, debug_batches // 4))\n",
    "\n",
    "inputs = Input(shape=(time_steps, num_features))\n",
    "x = layers.LSTM(32, recurrent_dropout=0.25)(inputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1)(x)\n",
    "lstm_model = Model(inputs, outputs)\n",
    "\n",
    "lstm_model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"mse\",\n",
    "    metrics=[\"mae\"],\n",
    ")\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor=\"val_mae\",\n",
    "    patience=2,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "history = lstm_model.fit(\n",
    "    lstm_train,\n",
    "    validation_data=lstm_val,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "\n",
    "test_loss, test_mae = lstm_model.evaluate(lstm_test)\n",
    "print(f\"Train MAE: {history.history['mae'][-1]:.2f} °C\")\n",
    "print(f\"Validation MAE: {history.history['val_mae'][-1]:.2f} °C\")\n",
    "print(f\"Test MAE: {test_mae:.2f} °C\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7fb7dc",
   "metadata": {},
   "source": [
    "### Try 5\n",
    "stacking RNN layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d1bcd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/20\n",
      "819/819 [==============================] - 104s 125ms/step - loss: 33.5239 - mae: 4.3813 - val_loss: 16.9930 - val_mae: 3.1807\n",
      "Epoch 2/20\n",
      "819/819 [==============================] - 102s 125ms/step - loss: 19.6760 - mae: 3.4707 - val_loss: 16.1882 - val_mae: 3.1607\n",
      "Epoch 3/20\n",
      "819/819 [==============================] - 103s 125ms/step - loss: 18.0445 - mae: 3.3191 - val_loss: 15.9455 - val_mae: 3.1536\n",
      "Epoch 4/20\n",
      "819/819 [==============================] - 103s 125ms/step - loss: 16.6902 - mae: 3.1885 - val_loss: 16.8907 - val_mae: 3.2779\n",
      "Epoch 5/20\n",
      "819/819 [==============================] - 102s 125ms/step - loss: 15.3300 - mae: 3.0474 - val_loss: 16.9818 - val_mae: 3.2825\n",
      "404/404 [==============================] - 10s 24ms/step - loss: 17.7145 - mae: 3.3138\n",
      "Training MAE: 3.05 °C\n",
      "Validation MAE: 3.15 °C\n",
      "Test MAE: 3.31 °C\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "gru_train = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "gru_val = val_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "gru_test = test_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Stack GRU layers with dropout to regularize the recurrent model\n",
    "inputs = keras.Input(shape=(time_steps, num_features))\n",
    "x = layers.GRU(32, recurrent_dropout=0.5, return_sequences=True)(inputs)\n",
    "x = layers.GRU(32, recurrent_dropout=0.5)(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1)(x)\n",
    "stacked_gru_model = keras.Model(inputs, outputs)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_mae\",\n",
    "        patience=2,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "]\n",
    "\n",
    "stacked_gru_model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "history = stacked_gru_model.fit(\n",
    "    gru_train,\n",
    "    epochs=20,\n",
    "    validation_data=gru_val,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "train_mae = history.history[\"mae\"][-1]\n",
    "val_mae = min(history.history[\"val_mae\"])\n",
    "\n",
    "_, test_mae = stacked_gru_model.evaluate(gru_test)\n",
    "print(f\"Training MAE: {train_mae:.2f} °C\")\n",
    "print(f\"Validation MAE: {val_mae:.2f} °C\")\n",
    "print(f\"Test MAE: {test_mae:.2f} °C\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c371ae97",
   "metadata": {},
   "source": [
    "### Try 6\n",
    "\n",
    "bi-directional RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "220af8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "819/819 [==============================] - 7s 7ms/step - loss: 34.1327 - mae: 4.3478 - val_loss: 17.0312 - val_mae: 3.2301\n",
      "Epoch 2/20\n",
      "819/819 [==============================] - 6s 7ms/step - loss: 15.7457 - mae: 3.1380 - val_loss: 16.2235 - val_mae: 3.1491\n",
      "Epoch 3/20\n",
      "819/819 [==============================] - 6s 7ms/step - loss: 14.3200 - mae: 2.9888 - val_loss: 16.2865 - val_mae: 3.1655\n",
      "Epoch 4/20\n",
      "819/819 [==============================] - 6s 7ms/step - loss: 13.7482 - mae: 2.9283 - val_loss: 16.5286 - val_mae: 3.2029\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 18.4855 - mae: 3.4101\n",
      "Train MAE: 2.93 °C\n",
      "Validation MAE: 3.15 °C\n",
      "Test MAE: 3.41 °C\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "\n",
    "bidi_train = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "bidi_val = val_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "bidi_test = test_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "inputs = keras.Input(shape=(time_steps, num_features))\n",
    "x = layers.Bidirectional(layers.LSTM(16))(inputs)\n",
    "outputs = layers.Dense(1)(x)\n",
    "bidirectional_model = keras.Model(inputs, outputs)\n",
    "\n",
    "bidirectional_model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor=\"val_mae\",\n",
    "    patience=2,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "history = bidirectional_model.fit(\n",
    "    bidi_train,\n",
    "    epochs=20,\n",
    "    validation_data=bidi_val,\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "\n",
    "test_loss, test_mae = bidirectional_model.evaluate(bidi_test)\n",
    "print(f\"Train MAE: {history.history['mae'][-1]:.2f} °C\")\n",
    "print(f\"Validation MAE: {min(history.history['val_mae']):.2f} °C\")\n",
    "print(f\"Test MAE: {test_mae:.2f} °C\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
